{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization,GRU,Reshape,Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import csv\n",
    "from captcha_gen import generate\n",
    "\n",
    "\n",
    "LETTERSTR = \"0123456789ABCDEFGHJKLMNPQRSTUVWXYZ*\"\n",
    "\n",
    "\n",
    "def toonehot(text):\n",
    "    labellist = []\n",
    "    for letter in text:\n",
    "        onehot = [0 for _ in range(35)]\n",
    "        num = LETTERSTR.find(letter)\n",
    "        onehot[num] = 1\n",
    "        labellist.append(onehot)\n",
    "    return labellist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN model 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new NN Model\n",
    "def build_new_model():\n",
    "    print(\"Creating CNN model...\")\n",
    "    in_type =Input((60, 200, 3))\n",
    "    out = in_type\n",
    "    out = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "    out = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "    out = Dropout(0.1)(out)\n",
    "    out = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "    out = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "    out = Dropout(0.1)(out)\n",
    "    out = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "    out = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "    out = Dropout(0.1)(out)\n",
    "    out = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "    out = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "    out = Flatten()(out)\n",
    "    # out = Dropout(0.1)(out)\n",
    "    out = Reshape((2560,1))(out)\n",
    "    out = Dense(256, activation='relu')(out)\n",
    "    out = Dropout(0.1)(out)\n",
    "    out = Bidirectional(GRU(84))(out)\n",
    "    out = [\n",
    "        Dense(35, name='digit1', activation='softmax')(out),\\\n",
    "        Dense(35, name='digit2', activation='softmax')(out),\\\n",
    "        Dense(35, name='digit3', activation='softmax')(out),\\\n",
    "        Dense(35, name='digit4', activation='softmax')(out),\\\n",
    "        Dense(35, name='digit5', activation='softmax')(out),\\\n",
    "        Dense(35, name='digit6', activation='softmax')(out)\n",
    "          ]\n",
    "    model = Model(inputs=in_type, outputs=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.讀取檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "READING_SIZE=5000\n",
    "\n",
    "def laod_traindata():\n",
    "    print(\"Reading training data...\")\n",
    "    traincsv = open('./data/56_imitate_train_set/captcha_train.csv', 'r', encoding = 'utf8')\n",
    "    pic_lsit=[]\n",
    "    #控制讀取筆數_pic\n",
    "    for rowp in csv.reader(traincsv):\n",
    "        pic_lsit.append(str(rowp[0]) )\n",
    "    pic_lsit=pic_lsit[:READING_SIZE]\n",
    "    train_data = np.stack([np.array(Image.open(\"./data/56_imitate_train_set/\" + row + \".jpg\"))/255.0 for row in pic_lsit])\n",
    "    traincsv = open('./data/56_imitate_train_set/captcha_train.csv', 'r', encoding = 'utf8')\n",
    "    read_label = [toonehot(row[1]) for row in csv.reader(traincsv)]\n",
    "    train_label1 = [[] for _ in range(6)]\n",
    "    for arr in read_label:\n",
    "        for index in range(6):\n",
    "            train_label1[index].append(arr[index])\n",
    "    train_label1 = [arr for arr in np.asarray(train_label1)]\n",
    "    #控制讀取筆數_label\n",
    "    train_label = []\n",
    "    for w in train_label1:\n",
    "        train_label.append(w[:READING_SIZE])\n",
    "    return train_data,train_label\n",
    "\n",
    "def laod_validata():\n",
    "    print(\"Reading validation data...\")\n",
    "    valicsv = open('./data/56_imitate_vali_set/captcha_vali.csv', 'r', encoding = 'utf8')\n",
    "    vali_data = np.stack([np.array(Image.open(\"./data/56_imitate_vali_set/\" + row[0] + \".jpg\"))/255.0 for row in csv.reader(valicsv)  ]) #\n",
    "    valicsv = open('./data/56_imitate_vali_set/captcha_vali.csv', 'r', encoding = 'utf8')\n",
    "    read_label = [toonehot(row[1]) for row in csv.reader(valicsv)]\n",
    "    vali_label = [[] for _ in range(6)]\n",
    "    for arr in read_label:\n",
    "        for index in range(6):\n",
    "            vali_label[index].append(arr[index])\n",
    "    vali_label = [arr for arr in np.asarray(vali_label)]\n",
    "    return vali_data,vali_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Traing model (逐次訓練都記錄model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "Reading training data...\n",
      "Reading validation data...\n",
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "5000/5000 [==============================] - 130s 26ms/step - loss: 0.4984 - digit1_loss: 0.0078 - digit2_loss: 0.0466 - digit3_loss: 0.2761 - digit4_loss: 0.1240 - digit5_loss: 0.0311 - digit6_loss: 0.0127 - digit1_acc: 0.9992 - digit2_acc: 0.9946 - digit3_acc: 0.9574 - digit4_acc: 0.9872 - digit5_acc: 0.9974 - digit6_acc: 0.9986 - val_loss: 1.2605 - val_digit1_loss: 0.0365 - val_digit2_loss: 0.1063 - val_digit3_loss: 0.5688 - val_digit4_loss: 0.3899 - val_digit5_loss: 0.1182 - val_digit6_loss: 0.0407 - val_digit1_acc: 0.9932 - val_digit2_acc: 0.9870 - val_digit3_acc: 0.8382 - val_digit4_acc: 0.9054 - val_digit5_acc: 0.9718 - val_digit6_acc: 0.9908\n",
      "\n",
      "Epoch 00001: val_digit3_acc improved from -inf to 0.83820, saving model to ./data/model/imitate_56_model_1.h5\n",
      "Epoch 2/3\n",
      "5000/5000 [==============================] - 128s 26ms/step - loss: 0.4440 - digit1_loss: 0.0077 - digit2_loss: 0.0458 - digit3_loss: 0.2404 - digit4_loss: 0.1142 - digit5_loss: 0.0232 - digit6_loss: 0.0127 - digit1_acc: 0.9990 - digit2_acc: 0.9938 - digit3_acc: 0.9670 - digit4_acc: 0.9912 - digit5_acc: 0.9988 - digit6_acc: 0.9984 - val_loss: 1.1471 - val_digit1_loss: 0.0249 - val_digit2_loss: 0.0888 - val_digit3_loss: 0.5251 - val_digit4_loss: 0.3638 - val_digit5_loss: 0.1087 - val_digit6_loss: 0.0357 - val_digit1_acc: 0.9948 - val_digit2_acc: 0.9898 - val_digit3_acc: 0.8572 - val_digit4_acc: 0.9090 - val_digit5_acc: 0.9742 - val_digit6_acc: 0.9936\n",
      "\n",
      "Epoch 00002: val_digit3_acc improved from 0.83820 to 0.85720, saving model to ./data/model/imitate_56_model_1.h5\n",
      "Epoch 3/3\n",
      "5000/5000 [==============================] - 128s 26ms/step - loss: 0.3986 - digit1_loss: 0.0050 - digit2_loss: 0.0311 - digit3_loss: 0.2242 - digit4_loss: 0.1032 - digit5_loss: 0.0248 - digit6_loss: 0.0103 - digit1_acc: 0.9998 - digit2_acc: 0.9960 - digit3_acc: 0.9742 - digit4_acc: 0.9932 - digit5_acc: 0.9976 - digit6_acc: 0.9992 - val_loss: 1.1352 - val_digit1_loss: 0.0264 - val_digit2_loss: 0.0893 - val_digit3_loss: 0.5047 - val_digit4_loss: 0.3667 - val_digit5_loss: 0.1098 - val_digit6_loss: 0.0383 - val_digit1_acc: 0.9952 - val_digit2_acc: 0.9896 - val_digit3_acc: 0.8706 - val_digit4_acc: 0.9100 - val_digit5_acc: 0.9736 - val_digit6_acc: 0.9916\n",
      "\n",
      "Epoch 00003: val_digit3_acc improved from 0.85720 to 0.87060, saving model to ./data/model/imitate_56_model_1.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f12e40a5390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    print(\"loading model\")\n",
    "    model=load_model('./data/model/imitate_56_model.h5')\n",
    "except :\n",
    "    build_new_model()\n",
    "    print(\"building new model\")\n",
    "    \n",
    "train_data,train_label = laod_traindata()\n",
    "vali_data,vali_label = laod_validata()\n",
    "\n",
    "filepath=\"./data/model/imitate_56_model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_digit3_acc', verbose=1, save_best_only=True, mode='max')\n",
    "earlystop = EarlyStopping(monitor='val_digit3_acc', patience=3, verbose=1, mode='auto')\n",
    "tensorBoard = TensorBoard(log_dir = \"./logs\", histogram_freq = 1)\n",
    "callbacks_list = [checkpoint, earlystop, tensorBoard]\n",
    "model.fit(train_data, train_label, batch_size=150, epochs=3, verbose=1, validation_data=(vali_data, vali_label), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Traing model (每訓練10輪記錄一次model,每訓練完一輪更新traing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"loading model\")\n",
    "    model=load_model('./data/model/imitate_56_model.h5')\n",
    "except :\n",
    "    build_new_model()\n",
    "    print(\"building new model\")\n",
    "  \n",
    "\n",
    "for now_times in range(100):\n",
    "    print(\"#############################\")\n",
    "    print(\"######    Round:\",now_times,\"    ######\")    \n",
    "    print(\"#############################\")    \n",
    "    print(\"loading train data\")\n",
    "    train_data,train_label = laod_traindata()\n",
    "    \n",
    "    if now_times%10!=0 :\n",
    "        model.fit(train_data, train_label, batch_size=280, epochs=15, verbose=2)# 不紀錄model\n",
    "        generate(5000, \"./data/56_imitate_train_set/\",  ENGP=100, FIVEP=50, ENGNOLIMIT=True, filename=\"train\")\n",
    "        print(\"Creating data\")\n",
    "    else:\n",
    "        vali_data,vali_label = laod_validata()\n",
    "        filepath=\"./data/model/imitate_56_model.h5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_digit3_acc', verbose=1, save_best_only=True, mode='max')\n",
    "        earlystop = EarlyStopping(monitor='val_digit3_acc', patience=3, verbose=1, mode='auto')\n",
    "        tensorBoard = TensorBoard(log_dir = \"./logs\", histogram_freq = 1)\n",
    "        callbacks_list = [checkpoint, earlystop, tensorBoard]\n",
    "        model.fit(train_data, train_label, batch_size=150, epochs=3, verbose=1, validation_data=(vali_data, vali_label), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
